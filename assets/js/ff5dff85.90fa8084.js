"use strict";(self.webpackChunkdata_and_analytics=self.webpackChunkdata_and_analytics||[]).push([[5832],{3905:(e,a,t)=>{t.d(a,{Zo:()=>d,kt:()=>u});var i=t(7294);function n(e,a,t){return a in e?Object.defineProperty(e,a,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[a]=t,e}function o(e,a){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);a&&(i=i.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),t.push.apply(t,i)}return t}function r(e){for(var a=1;a<arguments.length;a++){var t=null!=arguments[a]?arguments[a]:{};a%2?o(Object(t),!0).forEach((function(a){n(e,a,t[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(t,a))}))}return e}function s(e,a){if(null==e)return{};var t,i,n=function(e,a){if(null==e)return{};var t,i,n={},o=Object.keys(e);for(i=0;i<o.length;i++)t=o[i],a.indexOf(t)>=0||(n[t]=e[t]);return n}(e,a);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)t=o[i],a.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var l=i.createContext({}),c=function(e){var a=i.useContext(l),t=a;return e&&(t="function"==typeof e?e(a):r(r({},a),e)),t},d=function(e){var a=c(e.components);return i.createElement(l.Provider,{value:a},e.children)},h="mdxType",p={inlineCode:"code",wrapper:function(e){var a=e.children;return i.createElement(i.Fragment,{},a)}},m=i.forwardRef((function(e,a){var t=e.components,n=e.mdxType,o=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),h=c(t),m=n,u=h["".concat(l,".").concat(m)]||h[m]||p[m]||o;return t?i.createElement(u,r(r({ref:a},d),{},{components:t})):i.createElement(u,r({ref:a},d))}));function u(e,a){var t=arguments,n=a&&a.mdxType;if("string"==typeof e||n){var o=t.length,r=new Array(o);r[0]=m;var s={};for(var l in a)hasOwnProperty.call(a,l)&&(s[l]=a[l]);s.originalType=e,s[h]="string"==typeof e?e:n,r[1]=s;for(var c=2;c<o;c++)r[c]=t[c];return i.createElement.apply(null,r)}return i.createElement.apply(null,t)}m.displayName="MDXCreateElement"},899:(e,a,t)=>{t.r(a),t.d(a,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var i=t(7462),n=(t(7294),t(3905));const o={sidebar_position:1,title:"8.1 | Modern data architecture - Theory and actual implementation",slug:"/8.1",tags:["Data architecture","Data wahrehouse","Data lake","Data lakehouse","Data mesh"]},r="8.1 | Modern data architecture - Theory and actual implementation",s={unversionedId:"book/chapter8/08-01-data-architecture",id:"book/chapter8/08-01-data-architecture",title:"8.1 | Modern data architecture - Theory and actual implementation",description:"Jon Cajacob, November 2024",source:"@site/docs/01-book/01-chapter8/08-01-data-architecture.md",sourceDirName:"01-book/01-chapter8",slug:"/8.1",permalink:"/8.1",draft:!1,tags:[{label:"Data architecture",permalink:"/tags/data-architecture"},{label:"Data wahrehouse",permalink:"/tags/data-wahrehouse"},{label:"Data lake",permalink:"/tags/data-lake"},{label:"Data lakehouse",permalink:"/tags/data-lakehouse"},{label:"Data mesh",permalink:"/tags/data-mesh"}],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1,title:"8.1 | Modern data architecture - Theory and actual implementation",slug:"/8.1",tags:["Data architecture","Data wahrehouse","Data lake","Data lakehouse","Data mesh"]},sidebar:"tutorialSidebar",previous:{title:"8 | Collection of topics",permalink:"/category/8--collection-of-topics"},next:{title:"8.2 | Data quality management",permalink:"/8.2"}},l={},c=[{value:"8.1.1 | Theory",id:"811--theory",level:2},{value:"Goal of a data architecture",id:"goal-of-a-data-architecture",level:4},{value:"Technical perspective: <em>Data warehouses, data lakes and data lakehouses</em>",id:"technical-perspective-data-warehouses-data-lakes-and-data-lakehouses",level:3},{value:"Organizational perspective: <em>Data mesh</em>",id:"organizational-perspective-data-mesh",level:3},{value:"Definition",id:"definition",level:3},{value:"Data requirements are specific to business domains",id:"data-requirements-are-specific-to-business-domains",level:3},{value:"Components of a data mesh",id:"components-of-a-data-mesh",level:3},{value:"Skilled people are mission critical",id:"skilled-people-are-mission-critical",level:3},{value:"Cross-domain collaboration as a key success factor",id:"cross-domain-collaboration-as-a-key-success-factor",level:3},{value:"Centrally managed master data",id:"centrally-managed-master-data",level:3},{value:"8.1.2 | Corporate reality and its challenges",id:"812--corporate-reality-and-its-challenges",level:2},{value:"Overview",id:"overview",level:3},{value:"Most typical issues observed",id:"most-typical-issues-observed",level:3},{value:"8.1.3 | Guidelines for an effective data architecture",id:"813--guidelines-for-an-effective-data-architecture",level:2}],d={toc:c};function h(e){let{components:a,...o}=e;return(0,n.kt)("wrapper",(0,i.Z)({},d,o,{components:a,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"81--modern-data-architecture---theory-and-actual-implementation"},"8.1 | Modern data architecture - Theory and actual implementation"),(0,n.kt)("p",null,(0,n.kt)("em",{parentName:"p"},"Jon Cajacob, November 2024")),(0,n.kt)("p",null,'Data architecture is a topic that is hard to grasp and no one really knows how a "good" architecture for your data landscape and its specifics actually looks like as theoretical ideas regularly collide with organizational reality. '),(0,n.kt)("p",null,"Concepts and ideas around data architecture are constantly changing with the evolution of technology and tools available to users accordingly. The world of business intelligence and analytics looks very different today than twenty years ago simply because today the software available is much more powerful and flexible while being less and less technical. Because of that, ownership of data processes are shifted away from central IT organizations to decentral business teams, commonly referred to as self-service."),(0,n.kt)("p",null,"In this article I will introduce the most popular architectural concepts that are relevant today, both from a technical and organizational viewpoint. In particular, we will look at a rather new model, the ",(0,n.kt)("strong",{parentName:"p"},"data mesh"),". An organizational model that embraces the current state and future of data and analytics in institutions. In the final chapter of this article, I will give my thoughts on what actually works well in practice and how an organization can get closer to an effective data architecture."),(0,n.kt)("h2",{id:"811--theory"},"8.1.1 | Theory"),(0,n.kt)("h4",{id:"goal-of-a-data-architecture"},"Goal of a data architecture"),(0,n.kt)("p",null,"Let's introduce the following simple idea:"),(0,n.kt)("p",null,"\u2014 The goal of a data architecture is to bring structure into how data is stored, refined, distributed and used within an organization."),(0,n.kt)("p",null,"In simplified terms, data is used for ",(0,n.kt)("strong",{parentName:"p"},"operational processes")," and ",(0,n.kt)("strong",{parentName:"p"},"analytics to support decision making"),". The focus of this book is the latter, so the following discussion will heavily lean into data architecture for business intelligence (BI) and analytics."),(0,n.kt)("p",null,"There are three main concepts of how a data architecture can look like from a technical viewpoint: ",(0,n.kt)("strong",{parentName:"p"},"Data warehouses"),", ",(0,n.kt)("strong",{parentName:"p"},"data lakes")," and ",(0,n.kt)("strong",{parentName:"p"},"data lakehouses"),". In addition, there is an overarching organizational concept I want to introduce, the so called ",(0,n.kt)("strong",{parentName:"p"},"data mesh"),"."),(0,n.kt)("h3",{id:"technical-perspective-data-warehouses-data-lakes-and-data-lakehouses"},"Technical perspective: ",(0,n.kt)("em",{parentName:"h3"},"Data warehouses, data lakes and data lakehouses")),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Data architecture",src:t(9993).Z,width:"1615",height:"907"})),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Summary of each model:")),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Data warehouse")," (DWH): The DWH is the oldest and most established concept for storing, refining and distributing ",(0,n.kt)("strong",{parentName:"p"},"structured data")," for analytical purposes. With an ETL process (extract, transform and load), data is prepared and loaded from source systems to the DWH into a relational database. There are usually strict (business) rules for how the data is modelled, how tables look like and relate to each other. ",(0,n.kt)("strong",{parentName:"p"},"Datamarts")," are use-case driven dimensional star models based on a DWH database and subsequently consumed with BI software. A DWH is usually developed and maintained by a ",(0,n.kt)("strong",{parentName:"p"},"centralized")," organization. Thus there is usually a bottleneck and a large backlog of change requests coming from the organization's users. Changes are implemented slow accordingly. Further, developing and operating a DWH requires substantial resources and financial investments.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Data lake:")," With the emergence of big data and machine learning applications, the data lake architecture became more relevant. In a data lake, both ",(0,n.kt)("strong",{parentName:"p"},"structured and unstructured data")," (e.g. free text, audio, video etc.) is stored and unlike for the DWH, there is usually no or only little effort in having the data structured, standardized, refined or tidy from a central or governance perspective. Normally, data is just simply sychronized from a data source to the data lake 1:1 without any refinement which happens only later when single data teams are working on specific use-cases with their specific toolset. Accordingly, costs are much lower but so is reliability compared to the DWH. Further, efficiency and collaboration overall is greatly reduced because of the lack of governance and standardization.")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Data lakehouse:")," The data lakehouse is a rather new concept which tries to combine the advantages of cheap data storage in a data lake with the reliability of a data warehouse. In essence, a ",(0,n.kt)("strong",{parentName:"p"},"meta data and governance layer")," (which includes ETL pipelines) provides the required structure to the data stored in the data lake. Data residing in the data lake is accessed by various applications via this structural layer. This concept relies on a powerful and flexible ",(0,n.kt)("strong",{parentName:"p"},"data platform solution")," which - if even available on the market - can lead to a vendor lock-in (i.e. you become dependable on one vendor). Further, solutions are built ",(0,n.kt)("strong",{parentName:"p"},"decentralized")," in business departments which requires skilled people accordingly."))),(0,n.kt)("p",null,"The ",(0,n.kt)("strong",{parentName:"p"},"pros and cons")," of the different technical concepts should become clear by now. A ",(0,n.kt)("em",{parentName:"p"},"DWH")," delivers reliable, well-structured data, however does so at significant costs and it cannot keep up with the volatile and fast-changing environment a corporation usually has to deal with. The ",(0,n.kt)("em",{parentName:"p"},"data lake")," is cheap but is most often really nothing more than a big pile of all kinds of data. Data teams have to build their own specific solutions that cannot be re-used by other teams due to a lack of a common platform / infrastructure which leads to the opposite of a streamlined data architecture overall. The ",(0,n.kt)("em",{parentName:"p"},"data lakehouse")," tries to solve these issues with decentralizing data ownership and the establishment of a shared centralized data platform, however at the risk of possible vendor lock-in and lack of skilled people."),(0,n.kt)("h3",{id:"organizational-perspective-data-mesh"},"Organizational perspective: ",(0,n.kt)("em",{parentName:"h3"},"Data mesh")),(0,n.kt)("h3",{id:"definition"},"Definition"),(0,n.kt)("p",null,"While the previously introduced concepts are technical in nature, the data mesh looks at data architecture from a more organizational viewpoint."),(0,n.kt)("p",null,"Again, let's introduce a simple definition:"),(0,n.kt)("p",null,"\u2014 A data mesh ",(0,n.kt)("strong",{parentName:"p"},"decentralizes")," data management into ",(0,n.kt)("strong",{parentName:"p"},"data domains")," (= business teams) that fully own their data pipelines, models and data products. All data domains ",(0,n.kt)("strong",{parentName:"p"},"collaborate")," on a unified ",(0,n.kt)("strong",{parentName:"p"},"data platform")," that provides a common infrastructure for data storage, pipelining (ETL), analytics, standards and governance, access permissions and data discoverability."),(0,n.kt)("h3",{id:"data-requirements-are-specific-to-business-domains"},"Data requirements are specific to business domains"),(0,n.kt)("p",null,"The data mesh acknowledges an important fact about business intelligence and analytics: Data requirements are specific to business domains and a centralized organization cannot deliver that (in time) and keep up with change requests. Accordingly, ownership of data pipelines to prepare data and resulting data models, reports and other applications are fully owned (developed & maintained) by the specific business teams (full self-service)."),(0,n.kt)("p",null,"Essentially, ownership of data preparation and resulting products is moved to where the knowledge about data content resides and where data is actually worked with. This not only increases speed and flexibility, but also renders most requirement engineering between a central IT organization and business teams obsolete."),(0,n.kt)("h3",{id:"components-of-a-data-mesh"},"Components of a data mesh"),(0,n.kt)("p",null,"The following illustration summarizes the idea of a data mesh on a high level:"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Data mesh",src:t(2650).Z,width:"1612",height:"902"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Data domains")," are basically business teams (or departments) that naturally have specific data requirements. Of course these requirements can overlap with other teams which makes ",(0,n.kt)("strong",{parentName:"li"},"cross-domain collaboration")," important, e.g. the controlling team prepares and owns the ledger of accounting transactions which is typically also needed in the sales team"),(0,n.kt)("li",{parentName:"ul"},"The data domains develop and maintain their own ",(0,n.kt)("strong",{parentName:"li"},"data preparation processes")," (ETL pipelines) to feed their BI applications with data. They also fully own their data models, reports or other applications (e.g. a machine learning applications). These elements are called ",(0,n.kt)("strong",{parentName:"li"},"data products")," and the teams have a natural interest in maintaining a good (data) quality of these products"),(0,n.kt)("li",{parentName:"ul"},"All teams work with the same ",(0,n.kt)("strong",{parentName:"li"},"centrally owned data platform"),". Simply speaking, this infrastructure should enable all teams to share a ",(0,n.kt)("strong",{parentName:"li"},"common language and toolset")," when it comes to storing, preparing and using data"),(0,n.kt)("li",{parentName:"ul"},"In order to enable teams a streamlined access to data sources, data is synced between sources and a ",(0,n.kt)("strong",{parentName:"li"},"data lake")," that is part of the overall infrastructure. Given that, read-permissions can be controlled (e.g. on a data container level) and the business teams don't have to deal with connectivity to source systems"),(0,n.kt)("li",{parentName:"ul"},"A modern platform provides different ",(0,n.kt)("strong",{parentName:"li"},"tools and languages")," to work with the data. While data scientists may prefer to work with ",(0,n.kt)("strong",{parentName:"li"},"Python or R"),", a data analyst may prefer to work with ",(0,n.kt)("em",{parentName:"li"},"SQL")," or a BI tool like ",(0,n.kt)("strong",{parentName:"li"},"Power BI"),". The way these tools are integrated in the platform (e.g. connect with data sources) must be standardized across domains"),(0,n.kt)("li",{parentName:"ul"},"The platform can give an overview of data products available with a ",(0,n.kt)("strong",{parentName:"li"},"data catalogue")," and ",(0,n.kt)("strong",{parentName:"li"},"data lineage"),". The former describes datasets available and fosters discoverability and cross-domain collaboration. The latter is about understanding how data flows from data sources to data products in the organization in order to find potential for future streamlining of pipelines"),(0,n.kt)("li",{parentName:"ul"},"Ideally, data products are scored with quality metrics to make ",(0,n.kt)("strong",{parentName:"li"},"data quality")," transparent and improve it")),(0,n.kt)("p",null,"From this, it should become clear that the ",(0,n.kt)("strong",{parentName:"p"},"data lakehouse architecture")," summarized before, is the most fitting technological setup for a data mesh."),(0,n.kt)("h3",{id:"skilled-people-are-mission-critical"},"Skilled people are mission critical"),(0,n.kt)("p",null,"Because we are decentralizing data ownership to business teams, it is critical that these teams have the necessary skills and knowhow to create and maintain their data products. "),(0,n.kt)("p",null,"Luckily, software in the area of business intelligence and analytics has become much more self-service oriented in the past decade, away from coding to ",(0,n.kt)("strong",{parentName:"p"},"low- or even no-code user interfaces"),". For example, with Power BI you can create a data model and data visualizations with only very little code if the requirements allow it. For more complex cases, there is still the possibility the use specific code, e.g. to create complex calculations with DAX. This flexibility is what makes these modern tools so powerful."),(0,n.kt)("p",null,"And because modern tools are low/no-code, a person with an analytical skillset and IT affinity can rather quickly learn to work with such tools. To boost learning in the organization, it is highly recommended to set up ",(0,n.kt)("strong",{parentName:"p"},"data communities")," to exchange lessons learned and to help each other along the way."),(0,n.kt)("h3",{id:"cross-domain-collaboration-as-a-key-success-factor"},"Cross-domain collaboration as a key success factor"),(0,n.kt)("p",null,"Not only should data communities be put in place to foster learning from each other, but also to ",(0,n.kt)("strong",{parentName:"p"},"re-use data products across business domains"),". A use-case that is often observed is the ",(0,n.kt)("em",{parentName:"p"},"accounting & controlling")," domain that owns the ",(0,n.kt)("em",{parentName:"p"},"ledger of financial transactions")," and the respective dataset. Very often, other teams like ",(0,n.kt)("em",{parentName:"p"},"sales")," or ",(0,n.kt)("em",{parentName:"p"},"risk")," are also in need of at least a part of that data. Instead of these teams re-creating the same data product, it makes much more sense to re-use what is already there."),(0,n.kt)("p",null,"Clearly, letting other teams use a data product, can mean more work for the team owning the data product, because surely there will be ideas and change requests coming from the other teams. Further, this leads to cross-domain dependencies. For data products that are heavily used in many domains, it can therefore make sense to centrally develop and maintain those. This is also the case for master data."),(0,n.kt)("h3",{id:"centrally-managed-master-data"},"Centrally managed master data"),(0,n.kt)("p",null,"If you look closely in the summary illustration above, you will notice that I explicitely mention master data as part of the data lake. It is often the case that master data tables are re-used across different domains and use-cases, like for example product master data, financial accounts or country master data (regional structure). You would be amazed in how many different variations a regional structure / country table can be prepared for the exact same company. "),(0,n.kt)("p",null,"Therefore, it is worth centrally maintaining these tables and ensuring data quality for the benefit of many data domains."),(0,n.kt)("h2",{id:"812--corporate-reality-and-its-challenges"},"8.1.2 | Corporate reality and its challenges"),(0,n.kt)("p",null,"Now that we have an idea of how an effective data architecture ideally looks like, let's discuss some of the typcially observed challenges and issues in corporate reality. My own practice has allowed me observe a multitude of different data architectures of small and medium companies as well as large sized, internationally operating, group of companies. From that experience, I believe to be in the position to write down the most important issues to be tackled when trying to bring structure in how data is used across an organization."),(0,n.kt)("h3",{id:"overview"},"Overview"),(0,n.kt)("p",null,"The following illustrates a typical real-world data architecture of a medium sized company and highlights various problems:"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Real-world data architecture",src:t(2381).Z,width:"1615",height:"904"})),(0,n.kt)("h3",{id:"most-typical-issues-observed"},"Most typical issues observed"),(0,n.kt)("ol",null,(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Outdated data:")," This can happen in any architecture but I still want to note it down here as it is important. Outdated data in a DWH (or any other data application for that matter) quickly makes users loose trust in the data"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Lack of data integration:")," It is often the case that various systems of an organization are not integrated in an existing data warehouse. Given that, users have to combine data exports with DWH data outside the DWH system (i.e. Excel)"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Huge backlog of change requests:")," Because a DWH (or any other important data application) is typically developed and maintained by a central IT organization, which is probably running at its capacity limits, there is often a large backlog of change requests coming from the business teams with which the IT team cannot possibly keep up with (see also no. 10)"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Legacy frontend applications:")," Frontend applications that are based on old, outdated technology are unfortunately more the norm than the exception. The effect of these unflexible, static reporting tools is that users have to export data to Excel and continue from there with their work"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Manual data exports to Excel:")," See no. 4 - because we cannot work with the outdated frontend, we have to manually export data each time we need to update our reporting or analysis"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Manual efforts to create reports:")," Here is where most inefficiencies can be found: The repeated, manual creation of reports and analysis. It is usually done with huge Excel files that in the worst case also link to other Excel files. Because so much time is spent with creating a report, there is not really time left to actually explore and analyze the data"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Static reports:")," The results of all manual efforts are static reports which are unable to answer ad-hoc questions. Unlike with a modern BI tool, KPIs cannot be simply reported with another breakdown (without additional considerate effort), cross-filtered with complex conditions or drilled into"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Deviating KPIs:")," This is a difficult challenge to deal with in any architecture: Reports that are created by different teams and share the same KPIs, which show different values. This happens because there is a lack of effort to standardize definitions across domains. Please note, also with a modern, decentralized setup, this remains difficult to solve"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Shadow data lakes (or BI systems):"),' Because the central IT organization is too slow with implementing new requirements, teams that heavily rely on data may start building their own "shadow" solutions. The marketing team may start to create their own "data lake" that ingests manual data exports from the DWH (because IT refuses to set up a direct interface) or accesses an API like Google Analytics. From an IT perspective, this is an unwanted scenario because often these solutions are developed and operated by a single person that has all the knowledge. Now if this person leaves the company, who will take care of the solution going forward?'),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Lack of IT resources:")," As more business processes are digitalized and analytics gets more important for competitiveness, pressure on IT organizations keeps rising. At the same time, there are budget restrictions and finding skilled people remains difficult. As a result, central IT organizations have a hard time keeping up with change requests from the organization on top of maintaining applications that are already in place. This leads to a bottleneck and business teams have to wait (too) long for their requirements to be implemented"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Lack of a common data platform:")," If there is no common data platform / infrastructure and no clear leadership or guidance on that matter, business domains will start to build their individual shadow applications. The problem gets worse with the passing of time because the more of these shadow solutions are in place, the harder it will be to integrate them in a unified data platform later"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Data scientists that are lost in the organization:")," A data scientist's job should be to build machine learning algorithms on top of datasets to support decision making processes. However, the reality is, that they will spend the majority of their time searching and cleaning data. In particular searching data is a considerate waste of resources but it is the often observed in reality because there is not really any cross-domain collaboration or a catalog of available datasets"),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Agile bureaucracy:")," The original agile manifesto for software development that was created in 2001",(0,n.kt)("sup",{parentName:"li",id:"fnref-1"},(0,n.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))," is based on simple, people and customer focused principles. Unfortunately, in today's world the way ",(0,n.kt)("em",{parentName:"li"},"agile"),' is used in medium and large size companies is anything but agile anymore. Rather, it has become a "framework" of fairly complicated and bureacratic processes with terms that only "agile specialists" really understand. In my own experience, these frameworks are slowing down progress, reducing the actual agility of the organization and it frustrates users as they have to wait and wait for their requirements to be considered in the next "PI planning iteration". Agile has become a commercial product that is sold by "agile coaches" and companies should be mindful about the implementation of such frameworks. Much rather use of the agile toolset what is useful for your specific situation'),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("em",{parentName:"li"},"Lacking data quality:")," Last but not least, a problem that will never go away, no matter the data architecture or tools used. However, there are some tactics to actively manage the topic and improve the situation, like for example making quality issues transparent with metrics and people responsible to improve them over time")),(0,n.kt)("p",null,"Given these typical issues, it is easy to conclude that there can be a lot of value in a modern data architecture."),(0,n.kt)("h2",{id:"813--guidelines-for-an-effective-data-architecture"},"8.1.3 | Guidelines for an effective data architecture"),(0,n.kt)("p",null,"volatile world\npros and cons"),(0,n.kt)("div",{className:"footnotes"},(0,n.kt)("hr",{parentName:"div"}),(0,n.kt)("ol",{parentName:"div"},(0,n.kt)("li",{parentName:"ol",id:"fn-1"},(0,n.kt)("a",{parentName:"li",href:"https://agilemanifesto.org/"},(0,n.kt)("ins",null,"Manifesto for Agile Software Development")),(0,n.kt)("a",{parentName:"li",href:"#fnref-1",className:"footnote-backref"},"\u21a9")))))}h.isMDXComponent=!0},9993:(e,a,t)=>{t.d(a,{Z:()=>i});const i=t.p+"assets/images/img_book_02-7.2-023bd9d12387d908f1ff0a21e1ea9740.png"},2650:(e,a,t)=>{t.d(a,{Z:()=>i});const i=t.p+"assets/images/img_book_04-1-98213ffc07b3ac3750eb110ac018066d.png"},2381:(e,a,t)=>{t.d(a,{Z:()=>i});const i=t.p+"assets/images/img_book_04-2-574178a8283aaca41b370543dfdc66c9.png"}}]);